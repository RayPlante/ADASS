
\resetcounters

\bibliographystyle{asp2010}

\markboth{Redman and Dowler}{CAOM-2 at CADC}

\title{Implementing a Common Database Architecture at the CADC using CAOM-2}
\author{Russell~O.~Redman and Pat~Dowler}
\affil{National Research Council of Canada, 5071 West Saanich Road, Victoria, B. C., Canada V9E 2E7}

\aindex{Redman, R. O.}
\aindex{Dowler, P.}

\begin{abstract}
Significant progress has been made in implementing a common database architecture based on the Common Archive Object Model (CAOM-2). The first small archives have been successfully ingested into the new database structure, with the larger and more dynamic archives to follow over the next few months. 
\end{abstract}

\section{CAOM-2}
The Common Archive Object Model version 2 (CAOM-2) is the new database model to be used for all CADC archives, as was announced at ADASS XXI P037 \citet{P037_adassxxi}.  The structure of CAOM-2 captures the essential elements that our experience has shown to be essential to productive archive operations, allowing users to locate and download relevant data.  Online documentation providing a detailed description of CAOM-2 can be found at:
\begin{center}
 \url{http://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/caom2/}
 \end{center}  
A quick summary of the backbone of the model is:
\begin{itemize}
\item {\bf Artifact:} the normal unit of download, which is usually a file, or a tarball containing related files.  Alternatively, an artifact might be a row in a database, or an AIPS++ measurement set.  Artifacts are classified by their type, which is one of (science, calibration, auxiliary, info, preview).  Users can reduce download times and disk space requirements by requesting cutouts of large datasets and by choosing to download only artifacts of a particular type.
\item {\bf Plane:} group together artifacts that would normally be downloaded together, such as tiles within a large data cube, or image and weight files.
\item {\bf Provenance:} links planes that are related by the data flow during data reduction, capturing relations like ``raw $\rightarrow$ image + weight $\rightarrow$ catalog'', where there would be separate planes for ``raw'', ``image + weight'', and ``catalog'' files.
\item {\bf Observation:} groups together sets of planes derived from a common set of photons.  This captures the normal telescopic concept of a ``observation'' and generalizes it to the sets of files generated during data reduction.  
\item {\bf Repository:} a generic database that contains instances of all observation metadata, with conversions to/from xml.  The CAOM-2 searchable database is ``harvested'' from the repository, filling additional columns that are generated algorithmically from the supplied metadata to improve the performance of queries. 
\end{itemize}

An important property of CAOM-2 is that the actual data is referenced through URIs in the database that are expanded to URLs by the server.  This allows the data to be stored separately from the archive database, possibly on external servers that may be geographically remote.  We anticipate maintaining VO portals at the CADC for data from the next generation of observatories that will be too large to deliver directly to users over the internet.  It should still be possible to locate and download cutouts from these very large datasets using the CAOM-2 databases and CADC download software.

\section{Ingestion Software}
Much of the effort over the last year has gone into developing software to ingest data from our existing archives into the new model.  This starts with a detailed analysis of the available metadata, which can be archive-dependent constants, derived from file headers, read from observatory-supplied databases, or calculated from other metadata.  This analysis is publicly accessible, and for the archives that are currently being ported can be found in the CAOM-2 community wiki at: 
\begin{center}
{\small \url{https://wiki.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/caom2/index.php/Main_Page}}  
\end{center}
Note that anyone can read these pages, but only authorized members of the community can edit them.  

The process in outline is to divide a set of files into observations identified by a unique observationID string, sort the files into planes identified by a productID string that must be unique within each observation, and then generate an xml file that defines the CAOM-2 structure of all the files in the observation.  It is possible to fetch from the repository the xml representation of an existing observation and add, modify or remove planes and artifacts.  The xml file can then be written back to the repository to create or update the observation.

Many planes contain FITS files, and the appropriate tool to maintain planes of FITS files is the java program fits2caom2.  In most cases, it is not practical to generate calls to fits2caom2 manually, but a Python module ingest2caom2 has been written that handles most of the organizational details and can be customized without much work for individual archives.  In other cases, the metadata will be read from a database or describes data stored in non-FITS file formats.  A Python package pyCAOM2 has been written that allows data providers to generate xml files from arbitrary data sources.  This package can also be used to supplement the metadata in planes generated by fits2caom2.  

Moving the xml files out of and into the repository is handles by the program caom2repoClient, which is written in Python and can be imported as a Python module.
 
All the CAOM-2 ingestion software will be made open-source.  For portability, it is largely written in Java and Python 2.7.  (Porting the Python code to Python 3 awaits the availability of several major packages that are needed in daily operations and have not yet themselves been ported.) 
The choice of Python 2.7 was guided by several considerations:
\begin{itemize}
\item Free
\item Run anywhere (especially, in the CANFAR cloud and at remote observatories)
\item Widely understood by the current generation of programmers
\item Code is easy to customize for each observatory and instrument
\end{itemize}

The initial archives we have ported are BLAST, CGPS, and IRIS.  These are the three smallest archives at the CADC, but contain much of the same complexity that is present in larger archives.  The full end-to-end suite of software is running on test servers at the CADC, but will not be made publicly available until the software stabilizes at the end of development.  These three small archives allow us to test the software and are being regenerated fairly regularly as new features are added to the software.

Work is also under way to port the larger and more challenging archives for the CFHT, GEMINI, JCMT, and HST, with the remaining archives to follow.

\bibliography{editor}
