\documentclass[11pt,twoside]{article}
\usepackage{asp2010}
\resetcounters
\bibliographystyle{asp2010}

\markboth{Carrasco Kind, M. \& Brunner, R.~J.}{Implementing Probabilistic Photometric Redshifts}

\begin{document}

\title{Implementing Probabilistic Photometric Redshifts}
\author{Matias Carrasco Kind and Robert J. Brunner
\affil{Department of  Astronomy, University of Illinois, Urbana, IL 61820 USA}}


\begin{abstract}
Photometric redshifts have become more important with the growth of large imaging surveys. But their basic implementation has not changed significantly from their original development, as most techniques provide a single estimate and a computed error for the source redshift. In this paper, we present a new approach that provides accurate probability density functions (PDF) of redshifts for galaxies taken from the DEEP2 survey  by efficiently combining standard template fitting techniques with powerful machine learning methods in a new, fully probabilistic manner.
\end{abstract}

\section{Introduction}
Photometric redshift (hereafter photo-$z$) estimation techniques have become crucial for modern, multi-band digital surveys. And this need for fast and accurate photo-$z$ estimation is becoming even more important for current and future large photometric surveys like the Dark Energy Survey (DES) and the Large Synoptic Survey Telescope (LSST), which are probing galaxies that are often too faint to be spectroscopically observed. 

There are currently several different approaches for computing photometric redshifts~\citep[see, \textit{ e.g.},][for an updated comparison of current photometric redshift methods and public codes]{Hildebrandt2010,Abdalla2011} that depend partly on the object of interest as well as the accuracy required. Very few techniques are specifically designed to scale to several hundred million galaxies, and those that do generally only provide a single photo-$z$ estimate with a corresponding error. Most of these techniques are either template fitting based~\citep[\textit{e.g.,}][]{Benitez2000} or empirical training codes~\citep[\textit{e.g.,}][]{Carrasco2013}. Currently, no published technique combines two different methods in a self-consistent, probabilistic manner to provide accurate redshift probability density functions (PDFs).

In this paper, we present a new, robust photo-$z$ estimator that efficiently provides accurate redshift PDF's. We accomplish this by combining a template fitting method with a newly developed, parallel, machine learning photo-$z$ code, TPZ~\citep{Carrasco2013} that uses prediction trees and random forest techniques. This combined method provides individual photo-$z$ PDFs and ancillary information about the photo-$z$ estimation process in a unique manner.

\section{Method}
\articlefiguretwo{O06_f1a.eps}{O06_f1b.eps}{method}{A demonstration of our technique by using the DEEP2 data. (\textit{Left}) Our template redshift PDF estimation process. (top) The likelihood for a single galaxy to be one of the different spectral templates. (middle) The computed prior for this galaxy by using a RNBC process on the training data. (bottom) The final PDF computed with (solid line, orange area) and without (dashed line, gray area) the use of prior information. The vertical line shows the true redshift for this galaxy. (\textit{Right}) A sample of one binary prediction tree build with TPZ plotted radially. The initial node is close to the center of the figure. Colors are related to magnitudes and at the end of each leaf a prediction is made based on the information contained inside.}

Our algorithm consists of three distinct steps. First, we use a template fitting method to obtain likelihoods in the photo-$z$/color space by using either observed or synthetic spectra; in a quantitatively similar manner as~\cite{Benitez2000}. Within this Bayesian framework and given a suitable training sample, we compute accurate priors by using a novel Random Naive Bayes Classifier (RNBC). We also apply a principal component analysis in order to reduce strong correlations between the different attributes. 

By applying Bayes theorem, we can write the probability of a galaxy having redshift $z$ given its $n$ photometric magnitudes $m_i$ as:
\begin{equation}\label{bayes}
p(z|m_1,...,m_n) \propto \sum_T p(z,T|m_1,...,m_n)p(m_1,...,m_n|z,T)
\end{equation}
where the sum is for all spectral types $T$. The term $p(m_1,...,m_n|z,T)$ on the right hand side is the likelihood, which is obtained by using a set of templates, while the term $p(z,T|m_1,...,m_n)$ is the prior, which provides extra information for the Bayesian inference. 

By using available training data and RNBC, we have developed a new method to compute the individual galaxy priors:
\begin{equation}\label{prior}
 p(z,T|m_1,...,m_n) \propto p(z)p(T|z)\prod_{i=1}^{n} p(m_i|z,T)
\end{equation}
where $p(z)$ and $p(T|z)$ are computed from the training set and the term $p(m_i|z,T)$ is computed assuming a normal distribution with mean and variance computed from the training set. Priors are built by aggregating the results of several hundred bootstrap samples. We use a random subset of magnitudes in each bootstrap, similar to the construction of a random forest~\citep{Breiman2001}. The left panel of Figure~\ref{method}  demonstrates how a prior can improve the estimation of a redshift PDF. In this case, if no prior is used, a misclassification will occur without warning as the original likelihood gives a smooth and well peaked PDF at the wrong redshift for the wrong type (\textit{i.e.}, Spiral).

The second step is computing redshift PDFs by using prediction trees (as the one shown in the right panel of Figure~\ref{method}). Our implementation, called TPZ, requires the construction of a large number of prediction trees to create a forest. Extra information is provided so we are able to either incorporate existing training data in an efficient manner or to recommend specific new observations of additional data to improve the overall efficacy of our redshift PDF estimation. We are also able to identify the most important attributes or magnitudes, which can improve future photo-$z$ PDF construction.


As these are independent methods that have different origins, they have little or no covariance; therefore, the final step combines both of these redshift PDFs. We use the training sample to identify the regimes where each method performs best, and weight their individual redshift PDFs accordingly when computing a final redshift PDF. This powerful combination enables us to obtain a robust PDF and also to better identify catastrophic failures. Our algorithm runs in parallel by using MPI, and can be easily executed on large clusters to more easily process the massive data being obtained from large photometric surveys.

\section{Results}
We have tested this approach by using the latest release (DR4) of the DEEP2 survey that includes secure and accurate spectroscopy for over 27,000 sources. These data include photometry in three bands from the CFHT 12K: $B$, $R$, and $I$, and they have recently been extended~\citep{Matthews2012} by cross-matching the data to two other  ($u$, $g$, $r$, $i$, and $z$) photometric surveys: the CFHLS, and the SDSS.
We only select sources that are securely classified as galaxies, have secure redshifts, and a full set of photometric measurements. Since the data from these two surveys come from different telescopes and instruments, we treat those galaxies with SDSS photometry on fields 2, 3, and 4 of the DEEP2 independently from those with CFHLS photometry on field 1. This leaves us with a total of 19,699 galaxies with redshifts up to 1.5 and eight band photometry, of which we use a total of 10,000 randomly selected galaxies (approximately half of the data) for training and retain the rest for testing. 
\begin{table}
\caption{A comparison between the different steps in our photo-$z$ PDF estimation for the DEEP2 test data. We use the mean of each redshift PDF for these calculations.}
\label{tab:comparison}
\centering
\begin{tabular}{|l|r|r|r|r|}
\hline
\hline
 Method &  mean $\Delta z$ & $\sigma_{\Delta z}$ & outliers \\
\hline
Template flat prior (all)              &  0.0521  & 0.1422  & 27.06\\
Template + RNBC prior (all)            &  0.0428  & 0.1333  & 25.18\\
TPZ only       (all)                   & -0.0113  & 0.1034  & 14.54 \\
TPZ + Template + RNBC (all)            & -0.0077  & 0.0721  & 5.86 \\
TPZ + Template + RNBC ($zConf > 0.6$)  & -0.0051  & 0.0472  & 3.32\\
\hline
\end{tabular}
\end{table}

We  compute the bias as $\Delta z = (z_{\rm spec}-z_{\rm phot})/(1+z_{\rm spec})$, its dispersion $\sigma_{\Delta z}$, and the fraction of outliers with $|\Delta z| > 0.1$ for each step in our process and we compare the results in Table~\ref{tab:comparison} (for simplicity we use the mean of each redshift PDF in these calculations). The final row provides an additional result that includes a cut to the data based on the confidence interval of each individual PDF around the mean (in this specific case, we only keep data whose redshift PDF includes 60\% of the area around the mean between $z_{\rm phot} \pm \sigma_{z}(1+z_{\rm phot})$, where $\sigma_z$ = 0.05, \textit{i.e.}, the intrinsic scatter of this algorithm. The left panel of Figure~\ref{results} presents a combination of redshift PDFs, and three separate redshift PDFs with different confidence levels around the mean. The right panel of Figure~\ref{results} presents our final results for the 8,623 galaxies (after the cut of $zConf > 0.6$ is applied). We see a consistent result across all redshift ranges with an increase in the scatter toward higher redshifts due to poor SED templates and higher errors in the magnitudes. 

\articlefiguretwo{O06_f2a.eps}{O06_f2b.eps}{results}{Results from our algorithm.~(\textit{Left}) The upper left panel demonstrates how both PDFs can be combined, while the other three panels present PDFs differentiated by $zConf$, note how a higher $zConf$ produces a narrower PDF centered around the mean. The vertical dashed line corresponds to the spectroscopic value for the test galaxy and the gray area represents the confidence level.~(\textit{Right}) A TPZ+Template+RNBC with $zConf > 0.6$ photometric vs. spectroscopic redshift for 8,623 galaxies. The red dots are the median of $z_{\rm phot}$ for a given spectroscopic bin and the errors bars show the 10\% and 90\% percentiles.}

\section{Conclusions}
We have developed a new photo-$z$ PDF estimation technique that combines two complimentary techniques, building on their individual, implicit advantages to reliably compute distances to extragalactic sources. Training data are used to construct individual prior probabilities that improve the standard likelihood method for a template fitting technique. These data also are used to compute photo-$z$ PDFs by using TPZ, a machine learning technique that on average produces better redshift estimates than the template technique including RNBC. Our approach is also able to produce ancillary information that can be used to increase the accuracy of our redshift predictions, while also increasing the efficacy of supplemental training observations.

\bibliography{../../editor}

\end{document}	